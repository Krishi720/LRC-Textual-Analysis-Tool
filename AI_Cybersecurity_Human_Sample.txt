Human text on AI's role in Cybersecurity:
Machine learning is designed to train a computer to complete a certain task on its own. It is expected to change the cyberspace landscape in several ways.
First, new algorithms using machine learning are more adaptive, offering enhanced dynamism. Because cybersecurity risks evolve quickly over time, new generations of malware and cyberattacks are difficult to detect with traditional cybersecurity protocols. Machine learning overcomes this weakness by allowing cybersecurity systems to use pre-existing cyberattack data to respond to similar attacks.
Second, machine learning reduces the need for human labour in cybersecurity interactions, both in terms of offence and defence. A typical example of this would be spear-phishing, which tricks a specific individual or organization into leaking confidential information. Traditional methods of spear-phishing are often of limited scope. Effective intrusion requires a large amount of research on the potential target. Moreover, it is difficult, if not unfeasible, to attack multiple targets simultaneously. Yet, with the help of machine learning, automation of spear-phishing may be possible.
The third area in which machine learning may make a difference is attribution.
With more powerful learning capabilities, these algorithms are better able to locate critical evidence to reveal the real identity of an attacker, for example if certain code fragments mimic existing malware structures.
Despite its extensive use, the concept of cyber-deterrence remains unclear and under debate. There is disagreement over whether cyberattacks could be effectively deterred and even about whether the notion of deterrence is meaningful in cyberspace. However, according to those who are in favour of cyber-deterrence, it is feasible when certain conditions are met. For example, cyber-deterrence may work when it makes the cost of cyberattack exceptionally high. This can be achieved either by enhancing cyber-defence, thus enabling ‘deterrence by denial’, or by making retaliation credible and powerful, thus enabling ‘deterrence by punishment’. Another condition is that, unlike the traditional notion of deterrence, cyber-deterrence cannot be absolute. This means that some kinds of actor and some types of action cannot be deterred. Deterrence is most likely to work when attempting to deter cyberattacks that would have severe consequences and strategic purposes. Normally such attacks are planned and conducted by states.
A related condition is that the problem of attribution of an attack can be resolved to a degree when the strategic context and operational reality are taken into consideration. This leads to greater confidence that a cyberattack has been initiated by a state actor, as was the case with the use of the Stuxnet worm against Iranian nuclear facilities. The level of intelligence and technological capabilities required to carry out such an attack narrows down the list of suspects. In other words, attribution becomes less of a problem if the target of deterrence is a state, particularly a powerful one, and the behaviour to be deterred is a sophisticated, strategic cyberattack against an air-gapped facility. This has impli¬cations through¬ out civilian and military nuclear infrastructure.
Considering these conditions, the impact of machine learning on cyber-deterrence is ambiguous. On the one hand, cyber-deterrence may be enhanced. A typical example is in cyber-defence. By providing more active and adaptive defence, reducing human effort in monitoring threats and generating a timelier response, machine learning may raise the cost for a potential attacker and thus help promote deterrence by denial in cyberspace. Attribution is another area that machine learning may bolster. Deterrence would seem more credible if the attacker were to lose its anonymity. As such, cyber-deterrence could be more feasible with the intervention of machine learning.
Even if the above conditions are met, several factors may also reduce the effectiveness of cyber-deterrence.
The first is the possibility of adversarial machine learning. As cyber-defence models based on machine learning become more effective at detecting threats, potential attackers may look for ways to confuse the models. This is often called adversarial machine learning. Even if actors on the defensive side can rely on AI models to safeguard their systems, their confidence in deterrence by denial must not be exaggerated. This is because offenders may succeed in poisoning the models (also known as machine learning poisoning) or may find other ways to evade them. In this sense, the security benefits offered by AI could be offset. However, a 2018 report warned that relatively little attention has been paid to making AI-based defences robust against attackers that anticipate their use.5 Ironically, the use of machine learning for cyber-defence can actually expand the attack surface of a defence system—the points at which an attacker can interact with the system— due to this lack of attention and other vulnerabilities.
A second problem is the blurred connection between actors and capabilities. Strategic cyberattacks—attacks that inflict damage of strategic national impact— are currently unlikely to be conducted by individuals. Cyber operations that intend to change the target’s behaviour or to make the target bear considerable losses often involve complex efforts for preparation, organization, coordination, and testing and rehearsal. They necessitate an abundance of critical resources, such as discovery of zero-day vulnerabilities, hacking tools and talent. Such cyber operations also require adequate information about the target systems’ defence prepared¬ness. However, with the development of machine learning, these efforts could be performed or facilitated by automated and adaptive programmes. These pro¬grammes would be able to dig up vulnerabilities, circumvent detection, defeat anti-malware systems or even redesign an operation according to the recognized properties of the target system. This means that complex cyber operations may not require the same level of organizational complexity in the AI era. Individual hackers or small groups could also complete tasks that have strategic consequences. This would create several knock-on problems for cyber-deterrence. First, the ‘known identity plus known demand’ condition would be more difficult to establish—that is, being able to determine both the source of the attack and its aims would be muddied.6 Second, attribution would become more difficult because capabilities, including other forensic evidence such as language or similarity with past operations, may no longer be a reliable indicator for attribution. Third, cyberattacks with severe consequences may proliferate, undermining strategic stability in cyberspace.
Finally, increased use of AI in cybersecurity would make the gathering and sharing of data even more important. This may make alliance politics in cyberspace more common and intensive. Machine learning-based cyber-defence normally takes two forms. One is supervised learning, where the goal is to learn from known threats and to generalize and apply this knowledge to new threats. The other is unsupervised learning, in which programmes try to find suspicious deviations from normal behaviour. Either form would require extensive analysis of data and strong intelligence capabilities and networks. Therefore, to make deterrence effective, a state would need to cooperate with other states in information sharing in order to build a global intelligence network. This may encourage alliance relationships in cyberspace. The negative outcome would be an intensification of the already evident cleavages in cyberspace, creating a sense of antagonism between different groups and making global consensus on cybersecurity norms even harder to reach.
Overall, AI and machine learning pose risks and offer benefits to cybersecurity. The impact on cyber-deterrence remains unclear, since both defence and offence could be buttressed by the development of AI. This suggests the need for more dialogue among AI researchers, strategic researchers, policymakers and other relevant stakeholders to reach greater clarity on cyber-deterrence and how it may have an impact on future strategic relations and arsenals.

